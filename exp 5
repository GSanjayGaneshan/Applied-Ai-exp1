import numpy as np import pandas as pd
import matplotlib.pyplot as plt import tensorflow as tf
from sklearn.model_selection import train_test_split, StratifiedKFold from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ( confusion_matrix, classification_report, roc_auc_score, precision_recall_curve, auc,
roc_curve
)
from sklearn.utils.class_weight import compute_class_weight np.random.seed(42)
tf.random.set_seed(42)
df = pd.read_csv("creditcard.csv") X = df.drop("Class", axis=1)
y = df["Class"]
scaler = StandardScaler() X_scaled = scaler.fit_transform(X) print(df["Class"].value_counts()) classes = np.unique(y)
class_weights = compute_class_weight(
class_weight="balanced", classes=classes,
y=y
)
class_weight_dict = dict(zip(classes, class_weights)) class_weight_dict
//Implementation of DNN
def build_dnn(input_dim): model = tf.keras.Sequential([
tf.keras.Input(shape=(input_dim,)), tf.keras.layers.Dense(128, activation="relu",
kernel_regularizer=tf.keras.regularizers.l2(1e-4)), tf.keras.layers.BatchNormalization(), tf.keras.layers.Dropout(0.3),
tf.keras.layers.Dense(64, activation="relu",
kernel_regularizer=tf.keras.regularizers.l2(1e-4)), tf.keras.layers.BatchNormalization(), tf.keras.layers.Dropout(0.3),
tf.keras.layers.Dense(32, activation="relu",
kernel_regularizer=tf.keras.regularizers.l2(1e-4)),
tf.keras.layers.Dense(1, activation="sigmoid")
])
model.compile( optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss="binary_crossentropy",
metrics=["accuracy"]
)
return model
//Model evaluation
def evaluate_model(model, X_test, y_test): y_prob = model.predict(X_test).ravel() y_pred = (y_prob > 0.5).astype(int) roc_auc = roc_auc_score(y_test, y_prob)
precision, recall, _ = precision_recall_curve(y_test, y_prob) pr_auc = auc(recall, precision) print(confusion_matrix(y_test, y_pred)) print(classification_report(y_test, y_pred, digits=4))
return roc_auc, pr_auc, y_prob
//Plotting
def plot_curves(y_test, y_prob, title): fpr, tpr, _ = roc_curve(y_test, y_prob)
precision, recall, _ = precision_recall_curve(y_test, y_prob) plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1) plt.plot(fpr, tpr)
plt.plot([0, 1], [0, 1], linestyle="--") plt.xlabel("False Positive Rate") plt.ylabel("True Positive Rate") plt.title(f"ROC Curve – {title}") plt.subplot(1, 2, 2)
plt.plot(recall, precision) plt.xlabel("Recall") plt.ylabel("Precision") plt.title(f"PR Curve – {title}") plt.tight_layout()
plt.show()
//Experiment 1 — 80–20 Train–Test
X_train, X_test, y_train, y_test = train_test_split( X_scaled, y, test_size=0.2, stratify=y, random_state=42
)
model = build_dnn(X_train.shape[1]) model.fit(
X_train, y_train, epochs=30, batch_size=256,
class_weight=class_weight_dict, verbose=1
)
roc1, pr1, y_prob1 = evaluate_model(model, X_test, y_test) plot_curves(y_test, y_prob1, "Experiment 1 (80–20)")
//Experiment 2 — 70–30 Train–Test
X_train, X_test, y_train, y_test = train_test_split( X_scaled, y, test_size=0.3, stratify=y, random_state=42
)
model = build_dnn(X_train.shape[1]) model.fit(
X_train, y_train, epochs=30, batch_size=256,
class_weight=class_weight_dict, verbose=1
)
roc2, pr2, y_prob2 = evaluate_model(model, X_test, y_test) plot_curves(y_test, y_prob2, "Experiment 2 (70–30)")
//Experiment 3 — 60–20–20 Train–Val–Test
X_temp, X_test, y_temp, y_test = train_test_split( X_scaled, y, test_size=0.2, stratify=y, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42
)
early_stop = tf.keras.callbacks.EarlyStopping( monitor="val_loss", patience=5, restore_best_weights=True
)
model = build_dnn(X_train.shape[1]) model.fit(
X_train, y_train, validation_data=(X_val, y_val), epochs=50,
batch_size=256, class_weight=class_weight_dict, callbacks=[early_stop], verbose=1
)
roc3, pr3, y_prob3 = evaluate_model(model, X_test, y_test) plot_curves(y_test, y_prob3, "Experiment 3 (60–20–20)")
//Experiment 4 — 70–15–15 Train–Val–Test
X_temp, X_test, y_temp, y_test = train_test_split( X_scaled, y, test_size=0.15, stratify=y, random_state=42
)
X_train, X_val, y_train, y_val = train_test_split(
X_temp, y_temp, test_size=0.1765, stratify=y_temp, random_state=42
)
model = build_dnn(X_train.shape[1]) model.fit(
X_train, y_train, validation_data=(X_val, y_val), epochs=50,
batch_size=256, class_weight=class_weight_dict, callbacks=[early_stop], verbose=1
)
roc4, pr4, y_prob4 = evaluate_model(model, X_test, y_test) plot_curves(y_test, y_prob4, "Experiment 4 (70–15–15)")
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) roc_scores = []
pr_scores = []
for train_idx, test_idx in skf.split(X_scaled, y):
X_train, X_test = X_scaled[train_idx], X_scaled[test_idx] y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
model = build_dnn(X_train.shape[1]) model.fit(
X_train, y_train, epochs=1, # efficiency batch_size=256,
class_weight=class_weight_dict, verbose=0
)
y_prob = model.predict(X_test).ravel() roc_scores.append(roc_auc_score(y_test, y_prob)) precision, recall, _ = precision_recall_curve(y_test, y_prob)
pr_scores.append(auc(recall, precision))
print("ROC-AUC:", np.mean(roc_scores), "±", np.std(roc_scores)) print("PR-AUC:", np.mean(pr_scores), "±", np.std(pr_scores))
# Imbalance ratio (majority / minority) neg, pos = class_counts[0], class_counts[1] imbalance_ratio = neg / pos
print("Imbalance Ratio (Normal : Fraud) =", imbalance_ratio) import matplotlib.pyplot as plt
plt.figure() df['Class'].value_counts().plot(kind='bar') plt.xlabel("Class (0 = Normal, 1 = Fraud)") plt.ylabel("Count")
plt.title("Class Imbalance in Credit Card Dataset") plt.show()
print(f"Normal transactions : {neg}") print(f"Fraud transactions : {pos}")
print(f"Fraud percentage : {class_percentage[1]:.4f}%")
